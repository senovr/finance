{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bведение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный ноутбук основан на посте https://quantrum.me/875-parnyj-trejding-opisanie-strategii-na-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стратегия парного трейдинга очень популярна на рынке. Она основана на чистой статистике, что делает ее привлекательной для алгоритмической торговли. Общий смысл сводится к нескольким шагам: найти пару, проверить ее поведение, определить границы входа в позицию и направление (лонг/шорт).\n",
    "\n",
    "Пары ищут с помощью корреляции, но корреляция в чистом виде может сослужить плохую службу. Спред пар должен быть стационарным и обладать коинтегрированностью.\n",
    "\n",
    "В статье рассмотрены:\n",
    "\n",
    "Введение в корреляцию/коинтеграцию на простом примере.\n",
    "Корреляция без коинтеграции.\n",
    "Коинтеграция без корреляции."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основные понятия\n",
    "Временной ряд — статистические данные исследуемого процесса собранные в разные моменты времени.\n",
    "\n",
    "Корреляция — статистическая взаимосвязь двух и более случайных величин. В нашем случае временных рядов.\n",
    "\n",
    "Коинтеграция — свойство нескольких нестационарных временных рядов, заключающееся в существовании некоторой их стационарной линейной комбинации.\n",
    "\n",
    "Стационарность — свойство процесса не менять свои характеристики со временем.\n",
    "\n",
    "P-значение — величина используемая при тестировании статистических гипотез.\n",
    "\n",
    "Простыми словами: две акции будут коинтегрированы, когда спред разницы их истории цен будет находиться в пределах фиксированных границ и не будет обладать трендом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Пример на сгенерированных данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для начала сгенерируем два датасета.\n",
    "Второй - это то же самое что и первый, сдвинутый на некоторую величину и с добавленным случайным шумом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels\n",
    "from statsmodels.tsa.stattools import coint,adfuller\n",
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    " \n",
    "# устанавливаем зерно для повторимости случайных чисел\n",
    "np.random.seed(107)\n",
    " \n",
    "X_returns = np.random.normal(0, 1, 100) # генерируем историю доходности\n",
    "X = pd.Series(np.cumsum(X_returns), name='X') + 50 # суммируем и смещаем на произвольную величину\n",
    " \n",
    "some_noise = np.random.normal(0, 1, 100) # немного шума для второго ряда\n",
    "Y = X + 5 + some_noise\n",
    "Y.name = 'Y'\n",
    "pd.concat([X, Y], axis=1).plot() # рисуем оба ряда\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y-X).plot() # рисуем спрэд\n",
    "plt.axhline((Y-X).mean(), color='red', linestyle='--') # добавляем среднее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверив значения коинтеграции и корреляции, видим что спред пары стационарен, p-значение рядом с нулем, и имеет высокую корреляцию около 95%. Код для получения значений оценки ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_coint_corr(X, Y):\n",
    "    # проверим стационарность двух рядов\n",
    "    score, pvalue, _ = coint(X,Y)\n",
    "    # проверим корреляцию двух рядов\n",
    "    corr = X.corr(Y)\n",
    "    print(\"p-значение: %.4f\" % pvalue, \"корреляция: %s\" % corr)\n",
    "check_coint_corr(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дополнительно проведем тест Дики-Фуллера:\n",
    "    Он показывает, есть ли  зависимость от времени (тренд) внутри самой серии.\n",
    "    Если серия стационарна, полученное значение должно быть меньше чем critical value  (1% 5% или 10%- выбирать вам)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dft(X):\n",
    "    \"\"\"\n",
    "    X- pandas series.\n",
    "    \"\"\"\n",
    "    result = adfuller(X)\n",
    "    print(f'Checking {X.name} for stationarity')\n",
    "    score = result[0]\n",
    "    pvalue = result[1]\n",
    "    crit = result[4]\n",
    "    print(f'score is {score}')\n",
    "    print (f'p-value is {pvalue}')\n",
    "    print (f'critical values are {crit}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае мы не можем сказать, что серия стационарна (score > critical value для любого доверительного интервала).\n",
    "\n",
    "Теперь проверим разницу X-Y:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft(X-Y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае (как и ожидалось) разница двух рядов стационарна."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, есть случаи, когда ряды имеют высокую корреляцию без коинтеграции. Пара с таким свойством не подходит для парного трейдинга. Для изучения сформируем два независимых произвольных времянных ряда:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_returns = np.random.normal(1, 1, 100)\n",
    "Y_returns = np.random.normal(2, 1, 100)\n",
    "X_diverging = pd.Series(np.cumsum(X_returns), name='X')\n",
    "Y_diverging = pd.Series(np.cumsum(Y_returns), name='Y')\n",
    "pd.concat([X_diverging, Y_diverging], axis=1).plot()\n",
    " \n",
    "check_coint_corr(X_diverging, Y_diverging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И нарисуем спред:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Y_diverging-X_diverging).plot() # рисуем спрэд\n",
    "plt.axhline((Y_diverging-X_diverging).mean(), color='red', linestyle='--') # добавляем среднее"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что оба ряда имеют высокую корреляцию около 99% и проваливают тест на коинтеграцию с p-значением 0.881 (рядом с единицей). Мы видим, что спред имеет тенденцию роста со временем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же проведем тест Дики-фуллера на одной из переменных и на их разнице:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft(X_diverging)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Серия не стационарна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft(Y_diverging-X_diverging)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "То же самое можно сказать о разнице: если мы сравним с доверительным интервалом хотя бы 5% ( это означает что есть 5% вероятность того что полученные результаты случайны)- увидим что разница имеет тренд- что опять же не есть хорошо."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Реальный пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном примере мы возьмем две случайные акции, и проведем такой же визуальный анализ как показано выше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.append('../src/data')\n",
    "import ClickhouseHelper as chh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачаем минутные данные по ETF с начала 2020 года:\n",
    "\n",
    "    \n",
    "Кстати, ETF я использую исключительно для примера- размер получаемого датафрейма самый маленький.\n",
    "В дальнейшем подобный подход будем использовать на акциях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df=chh.query_data_by_time(\n",
    "    channels_list=[],\n",
    "    startTime=None,\n",
    "    endTime=None,\n",
    "    days_span=360,    \n",
    "    server_ip=\"192.168.1.128\",\n",
    "    table_name=\"minutes\",\n",
    "    instrument_type=\"Stock\",\n",
    "    data_freq=\"min\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# отфильтруем только по рублевым ETF\n",
    "df=df[df.currency=='RUB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# опять же для примера- нарисуем графики ETF vs Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15,15))\n",
    "\n",
    "for n, grp in df.groupby('ticker'):\n",
    "    ax.scatter(x = \"day\", y = \"c\", data=grp, label=n)\n",
    "ax.legend(title=\"Label\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что по коричневой и красным кривым ( FXUK, FXWO данные почему то скачались только до середины февраля.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Проверим длину ( количество значений) по каждому из ETF.\n",
    "#Для анализа критичным является то, что при сравнении и расчете коинтеграции и корелляции длина временных рядов должна быть одинаковой.\n",
    "all_lengths=[]\n",
    "for etf in df.ticker.unique():\n",
    "    print(f'shape of ETF {etf} {df[df.ticker==etf].name.unique()[0]} is: {df[df.ticker==etf].shape[0]}')\n",
    "    \n",
    "    all_lengths.append(df[df.ticker==etf].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_limit = int(np.percentile(all_lengths, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keeping only tickers with len>len_limit:\n",
    "for etf in df.ticker.unique():\n",
    "    if df[df.ticker==etf].shape[0]<=length_limit:\n",
    "        df = df[df.ticker != etf]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance(a):\n",
    "    \"\"\"\n",
    "    Конвертируем историю в относительные величины\n",
    "    \n",
    "    \"\"\"\n",
    "    a=a.values\n",
    "    return np.insert(np.cumsum(np.diff(a) / a[:-1] * 100.), 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Готовим данные для анализа: рассчитываем кумулятивную сумму дельт ( в % роста или падения от предыдущего дня)\n",
    "df['c_cumsum']=df.groupby('ticker')['c'].transform(get_performance)\n",
    "df['o_cumsum']=df.groupby('ticker')['o'].transform(get_performance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# проверяем коинтеграцию и удаляем стационарные ряды\n",
    "for ticker in df.ticker.unique():\n",
    "    result = adfuller(df[df.ticker==ticker].c_cumsum.values)\n",
    "    score = result[0]\n",
    "    pvalue = result[1]\n",
    "    crit = result[4]\n",
    "    if score<crit['1%']: \n",
    "        print(f'ticker {ticker} is cointegrated. Deleting it.')\n",
    "        df=df[df.ticker!=ticker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "for n, grp in df.groupby('ticker'):\n",
    "    fig, ax = plt.subplots(figsize=(8,2))\n",
    "    ax.scatter(x = \"day\", y = \"c_cumsum\", data=grp, label=n)\n",
    "    ax.legend(title=\"Label\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's pivot table for simplicity\n",
    "c_cumsum=df.pivot(index='day',columns='ticker',values='c_cumsum')\n",
    "o_cumsum=df.pivot(index='day',columns='ticker',values='o_cumsum')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующий шаг- выберем случайно две колонки и построим их значения, так же значения их разницы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cumsum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABRD=c_cumsum.ABRD\n",
    "AFKS=c_cumsum.AFKS\n",
    "pd.concat([ABRD, AFKS], axis=1).plot()\n",
    " \n",
    "check_coint_corr(ABRD, AFKS)\n",
    "\n",
    "plt.show()\n",
    "plt.figure()\n",
    "(ABRD-AFKS).plot() # рисуем спрэд\n",
    "plt.axhline((ABRD-AFKS).mean(), color='red', linestyle='--') # добавляем среднее\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видим, что оба ряда имеют низкую корреляцию около 10% и проваливают тест на коинтеграцию с p-значением 0.91 (рядом с единицей). Мы видим, что спред имеет временную зависимость."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем тест Дики-Фуллера:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft(ABRD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Серия не стационарна"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft(ABRD-AFKS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аналогично, данная серия не стационарна ( на горизонте 12-ти месяцев, и использовать ее нельзя)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Автоматический подбор пар"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну а сейчас - немного мяса. \n",
    "Давайте поищем пары среди ETF для парной торговли.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данный тест проверяет времянной ряд (историю изменения цены) на стационарность (наличие коинтеграции). Осуществляется проверка наличия у времянного ряда единичного корня, о чем подробнее написано в Вики. Реализован в библиотеке statsmodels.\n",
    "\n",
    "Функция проверки стационарности:\n",
    "[code python]statsmodels.tsa.stattools.adfuller(X)[/code]\n",
    "\n",
    "Выбираем пары с оценкой ниже 5% критического порога и p-значением меньше 0,001. Код поиска пар ниже:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cumsum.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cumsum.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cumsum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cumsum.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cumsum.dropna(axis=0, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_cumsum.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(c_cumsum.columns)\n",
    "score_matrix = np.zeros((n, n))\n",
    "pvalue_matrix = np.ones((n, n))\n",
    "\n",
    "symbols = c_cumsum.columns.to_list()\n",
    "pairs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            S1 = c_cumsum[symbols[i]]\n",
    "            S2 = c_cumsum[symbols[j]]\n",
    "            \n",
    "            # подготавливаем ряды, если надо\n",
    "            #if need_preparation:\n",
    "            #   S1, S2 = prepare_vectors(S1, S2, to_performance=True)\n",
    "                \n",
    "            # проверяем коинтеграцию\n",
    "            print(f\"comparing {S1.name} and {S2.name}\")\n",
    "            if S1.shape[0]==S2.shape[0]:\n",
    "                result = adfuller(S1-S2)\n",
    "                # заполняем матрицы значений\n",
    "                score = result[0]\n",
    "                pvalue = result[1]\n",
    "                crit = result[4]\n",
    "                score_matrix[i, j] = score\n",
    "                pvalue_matrix[i, j] = pvalue\n",
    "                # добавляем пары без единичных корней с p-значением менее 0.001\n",
    "                if score < crit['5%'] and pvalue < 0.001:\n",
    "                    pairs.append((symbols[i], symbols[j], pvalue))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сортируем пары по возрастанию p-значения\n",
    "import operator\n",
    "sorted_pairs = sorted(pairs, key=operator.itemgetter(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Давайте теперь сравним парочку значений более детально:\n",
    "MGNT=c_cumsum.MGNT\n",
    "TRMK=c_cumsum.TRMK\n",
    "pd.concat([MGNT, TRMK], axis=1).plot()\n",
    " \n",
    "check_coint_corr(MGNT, TRMK)\n",
    "\n",
    "plt.show()\n",
    "plt.figure()\n",
    "(MGNT-TRMK).plot() # рисуем спрэд\n",
    "plt.axhline((MGNT-TRMK).mean(), color='red', linestyle='--') # добавляем среднее\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cointegrated_pairs_adf(df, need_preparation=False):\n",
    "    # готовим матрицы для сбора оценок и p-значений\n",
    "    n = len(df.columns)\n",
    "    score_matrix = np.zeros((n, n))\n",
    "    pvalue_matrix = np.ones((n, n))\n",
    "    \n",
    "    symbols = df.columns.to_list()\n",
    "    pairs = []\n",
    "    \n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            S1 = symbol_prices[symbols[i]]\n",
    "            S2 = symbol_prices[symbols[j]]\n",
    "            \n",
    "            # подготавливаем ряды, если надо\n",
    "            if need_preparation:\n",
    "                S1, S2 = prepare_vectors(S1, S2, to_performance=True)\n",
    "                \n",
    "            # проверяем коинтеграцию\n",
    "            result = adfuller(S1-S2)\n",
    "            # заполняем матрицы значений\n",
    "            score = result[0]\n",
    "            pvalue = result[1]\n",
    "            crit = result[4]\n",
    "            score_matrix[i, j] = score\n",
    "            pvalue_matrix[i, j] = pvalue\n",
    "            # добавляем пары без единичных корней с p-значением менее 0.001\n",
    "            if score < crit['5%'] and pvalue < 0.001:\n",
    "                pairs.append((symbols[i], symbols[j], pvalue))\n",
    "                \n",
    "    # сортируем пары по возрастанию p-значения\n",
    "    sorted_pairs = sorted(pairs, key=operator.itemgetter(2))\n",
    "    return score_matrix, pvalue_matrix, sorted_pairs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DL_py37]",
   "language": "python",
   "name": "conda-env-DL_py37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
